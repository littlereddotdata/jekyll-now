for week 0 we hosted a series of workshops to deep dive into some fundamentals we thought were useful to emphasise from the get-go. Specifically, these fundamentals centred on: 

1. getting a lightning overview on the end-to-end machine learning production pipeline. 
2. setting up a reproducible development environment.

## 1. getting a lightning overview on the end-to-end machine learning production pipeline.
stages of the pipeline include: collecting data, annotating the data, deciding on an appropriate deep learning framework, training a model on the data and packaging the model as a API endpoint. 

what we wanted to capture here was the existing state of our apprentice's knowledge, and how that knowledge would develop over the course of the workshop. in other words, pedagogically we wanted to ["make learning visible"](http://www.pz.harvard.edu/projects/making-learning-visible). to this end, we created a shared Google Doc that people could edit live, listing down their initial ideas around building a machine learning product, and then eventually noting down what they had learnt and comparing the before and after.  

## 2. setting up a reproducible development environment. 
objectives of this workshop included pinning down what reproducibility might look like and how to execute it in practice. What the workshop protocol doesn't capture is the fun we had digging into different interpretations and implementations of reproducibility. some people suggested to always include a set of instructions for the end user so they can execute the code properly. other's also pointed out the importance of listing down the code's dependencies (not only the code). most memorably, someone posted a post-it with one word - "containers". there had been some introduction to containers in the previous day's workshop, and so there were some ideas floating around on how to use containers to package code, dependencies and runtime together. this was a good opportunity to weigh up the pros and cons of each approach, and kudos to Najib Ninaba, our resident reproducbility expert for pushing us to think criticially about the different approaches. also, this was a good chance to move into, again, what the fundamentals of reproduciblity might look like. Usually, this starts out with simple steps like: having a fixed and understandable folder structure for each project, and naming files to make them easily filterable by command line tools like sed/awk and grep. 

you can find the workshop outline [here:](https://github.com/kelaberetiv/aiap-field-guide/tree/master/week_0_workshops)
